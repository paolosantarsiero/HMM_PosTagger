{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from conllu import parse\n",
    "import math"
   ]
  },
  {
   "source": [
    "INIT TAG SETS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_g = ['ADJ','ADP','ADV','CCONJ','DET','INTJ','NOUN','NUM','PART','PRON','PUNCT','SCONJ','VERB','X'];\n",
    "tags_l = ['ADJ','ADP','ADV','AUX','CCONJ','DET','NOUN','NUM','PART','PRON','PROPN','PUNCT','SCONJ','VERB','X'];"
   ]
  },
  {
   "source": [
    "COUNTING TAG AND WORD'S TAG"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(word, tag, tagset, count_words, count_tag):\n",
    "    index_of_tag = tagset.index(tag);\n",
    "    totIndex = len(tagset);\n",
    "    # update count of tag\n",
    "    count_tag[index_of_tag] = count_tag[index_of_tag] + 1;\n",
    "    # update count of word\n",
    "    if(word in count_words.keys()):\n",
    "        count_words[word][index_of_tag] = count_words[word][index_of_tag] + 1;\n",
    "    else:\n",
    "        word_row = np.zeros(len(tagset) + 1, dtype=int);\n",
    "        word_row[index_of_tag] = 1;\n",
    "        count_words[word] = word_row;\n",
    "    # update total count of word\n",
    "    count_words[word][totIndex] = count_words[word][totIndex] + 1;\n",
    "    # update total count of tag\n",
    "    count_tag[totIndex] = count_tag[totIndex] + 1;\n",
    "    return count_words, count_tag;"
   ]
  },
  {
   "source": [
    "CALCULATE EMISSION PROBABILITY"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateEmissionProbability(word, tag, tagset, count_words, count_tag ,probEmission):\n",
    "    index_of_tag = tagset.index(tag);\n",
    "    # index for total count\n",
    "    totIndex = len(tagset);\n",
    "    #if word exist then update count\n",
    "    if(word in probEmission.keys()):\n",
    "        probEmission[word][index_of_tag] = count_words[word][index_of_tag] / count_tag[index_of_tag];\n",
    "    #if NTOT word exist then create row\n",
    "    else:\n",
    "        prob_row = np.zeros(len(tagset) + 1);\n",
    "        prob_row[index_of_tag] = count_words[word][index_of_tag] / count_tag[index_of_tag];\n",
    "        probEmission[word] = prob_row;\n",
    "    return probEmission;"
   ]
  },
  {
   "source": [
    "CALCULATE TRANSITION PROBABILITY"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateTransictionProbability(word, prev_tag, tag, tagset, transition, count_tag, nSentences, probTransition):\n",
    "    #natural sequence when scan senteces\n",
    "    trans_tag = \"%s_%s\" % (prev_tag,tag);\n",
    "    #Sequence used to saved\n",
    "    trans_tag_real = \"%s_%s\" % (tag,prev_tag);\n",
    "    \n",
    "    if(trans_tag in transition.keys()):\n",
    "        transition[trans_tag] = transition[trans_tag] + 1;\n",
    "    else:\n",
    "        transition[trans_tag] = 1;\n",
    "\n",
    "    #When tag is Q0 (start) the calculate probTransistion with number of sentences\n",
    "    #Else use normal Transition probability\n",
    "    if(trans_tag in probTransition.keys() and prev_tag != 'Q0'):\n",
    "        index_of_tag = tagset.index(prev_tag);\n",
    "        probTransition[trans_tag_real] = transition[trans_tag] /count_tag[index_of_tag];\n",
    "    else:\n",
    "        probTransition[trans_tag_real] = transition[trans_tag]/ nSentences;\n",
    "\n",
    "    return tag, probTransition;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(language,fileType):\n",
    "    nameFile = \"./corpus/%s/data_%s.conllu\" % (language,fileType);\n",
    "    tsv_file = open(nameFile,\"r\",encoding=\"utf-8\").read();\n",
    "    sentences = parse(tsv_file)\n",
    "    return sentences;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(language,statisticsIsEnabled):\n",
    "    #select tag sets of language choosen\n",
    "    if language == \"greek\":\n",
    "        tagset = tags_g;\n",
    "    elif language == \"latin\":\n",
    "        tagset = tags_l;\n",
    "    else:\n",
    "        raise Exception(\"Language not found!\");\n",
    "\n",
    "    # INIT DATA STRUCTURE\n",
    "    count_words = dict();\n",
    "    count_tag = np.zeros(len(tagset) + 1, dtype = int);\n",
    "    probEmission = dict();\n",
    "    probTransition = dict();\n",
    "    transition = dict();\n",
    "    statistics = np.zeros(len(tagset));\n",
    "\n",
    "    if statisticsIsEnabled == True:\n",
    "        statistics = calculateStatisticPosTagging(language)\n",
    "\n",
    "    #Count number of sentence for calculate probTransistio with tag start Q0\n",
    "    nSentences = 0;\n",
    "\n",
    "    sentences = readFile(language,\"train\")\n",
    "    for sentence in sentences:\n",
    "        prev_tag = 'Q0';\n",
    "        nSentences = nSentences + 1;\n",
    "        for token in sentence:\n",
    "            word = token[\"form\"];\n",
    "            tag = token[\"upos\"];\n",
    "            count_words, count_tag = count(word, tag, tagset, count_words, count_tag);\n",
    "            probEmission = calculateEmissionProbability(word,tag,tagset, count_words, count_tag, probEmission);\n",
    "            prev_tag, probTransition = calculateTransictionProbability(word, prev_tag, tag, tagset, transition, count_tag, nSentences, probTransition)\n",
    "    return sentences,tagset, probEmission, probTransition,statistics;"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence(sentence):\n",
    "    words = [];\n",
    "    for token in sentence:\n",
    "        words.append(token[\"form\"]);\n",
    "    return words"
   ]
  },
  {
   "source": [
    "CALCULATE STATISTIC POS TAGGIN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateStatisticPosTagging(language):\n",
    "    #select tag sets of language choosen\n",
    "    if language == \"greek\":\n",
    "        tagset = tags_g;\n",
    "    elif language == \"latin\":\n",
    "        tagset = tags_l;\n",
    "    else:\n",
    "        raise Exception(\"Language not found!\");\n",
    "\n",
    "    count_words = dict();\n",
    "    count_tag = np.zeros(len(tagset) + 1, dtype = int);\n",
    "    count_tag_one_occured = np.zeros(len(tagset), dtype = int);\n",
    "    count_tag_one_occured_total = 0;\n",
    "\n",
    "    statistics = np.zeros(len(tagset));\n",
    "    \n",
    "\n",
    "    sentences = readFile(language,\"dev\");\n",
    "    for sentence in sentences:\n",
    "        for token in sentence:\n",
    "            word = token[\"form\"];\n",
    "            tag = token[\"upos\"];\n",
    "            count_words, count_tag = count(word, tag, tagset, count_words, count_tag);\n",
    "\n",
    "    totIndex = len(tagset);\n",
    "    for word in count_words:\n",
    "        if count_words[word][totIndex] == 1:\n",
    "            index_of_tag = np.argmax(count_words[word]);\n",
    "            count_tag_one_occured[index_of_tag] = count_tag_one_occured[index_of_tag] + 1;\n",
    "            count_tag_one_occured_total =  count_tag_one_occured_total + 1;\n",
    "\n",
    "    for tag in tagset:\n",
    "        index_of_tag = tagset.index(tag);\n",
    "        statistics[index_of_tag] = count_tag_one_occured[index_of_tag] / count_tag_one_occured_total;\n",
    "    return statistics;"
   ]
  },
  {
   "source": [
    "IMPLEMENT SMOOTHING"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectSmoothing(type, probEmission, word, index_of_tag, tagset, statistics):\n",
    "    # NO SMOOTHING\n",
    "    if word in probEmission.keys():\n",
    "       return probEmission[word][index_of_tag]\n",
    "    elif type == 0 and word not in probEmission.keys():\n",
    "        return 0.00001;\n",
    "    # IF WORD NOT EXIST THEN SET NOUN PROBABILITY 1\n",
    "    elif type == 1 and word not in probEmission.keys():\n",
    "        prob_row = np.zeros(len(tagset) + 1);\n",
    "        index_of_noun = tagset.index(\"NOUN\");\n",
    "        prob_row[index_of_noun] = 1;\n",
    "        return prob_row[index_of_tag];\n",
    "    elif type == 2 and word not in probEmission.keys():\n",
    "        prob_row = np.zeros(len(tagset) + 1);\n",
    "        index_of_noun = tagset.index(\"NOUN\");\n",
    "        index_of_verb = tagset.index(\"VERB\");\n",
    "        prob_row[index_of_noun] = 0.5;\n",
    "        prob_row[index_of_verb] = 0.5;\n",
    "        return prob_row[index_of_tag];\n",
    "    elif type == 3 and word not in probEmission.keys():\n",
    "        unk_prob = 1 / len(tagset);\n",
    "        prob_row = np.full(len(tagset) + 1, unk_prob);\n",
    "        return prob_row[index_of_tag];\n",
    "    elif type == 4 and word not in probEmission.keys():\n",
    "        return statistics[index_of_tag];\n",
    "    else:\n",
    "        return 0.00001;"
   ]
  },
  {
   "source": [
    "DECODING WITH VITERBI"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def viterbi(sentence, tagset, probEmission, probTransition, smoothingType, statistics):\n",
    "    words = tokenize_sentence(sentence);\n",
    "    start_tag = \"Q0\";\n",
    "    viterbi_matrix = np.zeros((len(tagset),len(words)));\n",
    "    backtrace = np.zeros(len(words), dtype = int);\n",
    "    probabilites = np.zeros(len(words));\n",
    "    t = 0;\n",
    "   \n",
    "    for word in words:\n",
    "        # Calculate viterbi column for every tag possible\n",
    "        for tag in tagset:\n",
    "            index_of_tag = tagset.index(tag);\n",
    "            #Get Emission probabilty of word ( HERE WHEN CAN APPLY SMOOTHING)\n",
    "            probE = selectSmoothing(smoothingType, probEmission, word, index_of_tag, tagset, statistics);\n",
    "\n",
    "            #Run first iteration of viterbi to initialize first column\n",
    "            if t == 0:\n",
    "                tran_tag = \"%s_%s\" % (tag,start_tag);   \n",
    "                probT = 0.00001;\n",
    "                if tran_tag in probTransition.keys():\n",
    "                    probT = probTransition[tran_tag];\n",
    "                viterbi_matrix[index_of_tag][t] = probE * probT;\n",
    "            else:\n",
    "                max_tmp = np.zeros(len(tagset));\n",
    "                for i in range(0,len(tagset)):\n",
    "                    tran_tag = \"%s_%s\" % (tag,tagset[i]);\n",
    "                    probT = 0.00001;\n",
    "                    if tran_tag in probTransition.keys():\n",
    "                        probT = probTransition[tran_tag];\n",
    "\n",
    "                    max_tmp[i] = viterbi_matrix[i,t-1] * probT;\n",
    "                viterbi_matrix[index_of_tag,t] = np.amax(max_tmp) * probE;\n",
    "\n",
    "        index_max_values = np.argmax(viterbi_matrix[:,t]);  \n",
    "        backtrace[t] = index_max_values;\n",
    "        probabilites[t] = viterbi_matrix[index_max_values,t];\n",
    "        t= t +1;\n",
    "    return backtrace,probabilites;"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printPosTag(sentence, tagset, backtrace , probabilities):\n",
    "    i = 0;\n",
    "    words = tokenize_sentence(sentence);\n",
    "    for word in words:\n",
    "        print(\"WORD_ROW -> \" + word + \" \" + tagset[backtrace[i]] + \"     prob -> \" + str(probabilities[i]))\n",
    "        i = i + 1;"
   ]
  },
  {
   "source": [
    "TRAIN AND DECODING GREEK"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences_greek, tagset_greek, probEmission_greek, probTransition_greek, statistics_greek  =  train(\"greek\",False);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== TEST ON GREEK ================================== \n==================== new sentence ================================== \nWORD_ROW -> ἐρᾷ VERB     prob -> 9.435169962449398e-05\nWORD_ROW -> μὲν PART     prob -> 3.0217439910802045e-07\nWORD_ROW -> ἁγνὸς ADJ     prob -> 6.3622033860714765e-12\nWORD_ROW -> οὐρανὸς NOUN     prob -> 4.647743328610378e-16\nWORD_ROW -> τρῶσαι VERB     prob -> 6.075481475307685e-17\nWORD_ROW -> χθόνα NOUN     prob -> 6.873014278609289e-21\nWORD_ROW -> , PUNCT     prob -> 6.3728020354193885e-22\nWORD_ROW -> ἔρως NOUN     prob -> 9.112531392721117e-27\nWORD_ROW -> δὲ PART     prob -> 8.88091549905803e-29\nWORD_ROW -> γαῖαν NOUN     prob -> 3.223942481827329e-32\nWORD_ROW -> λαμβάνει VERB     prob -> 2.809535931875668e-33\nWORD_ROW -> γάμου NOUN     prob -> 1.1672227212595416e-37\nWORD_ROW -> τυχεῖν VERB     prob -> 9.961575636429551e-42\nWORD_ROW -> · PUNCT     prob -> 7.0319855982484075e-43\n==================== new sentence ================================== \nWORD_ROW -> ὄμβρος NOUN     prob -> 2.559161907362648e-05\nWORD_ROW -> δ̓ PART     prob -> 4.6325644254302794e-07\nWORD_ROW -> ἀπ̓ ADP     prob -> 4.082108893839203e-10\nWORD_ROW -> εὐνάοντος ADJ     prob -> 2.946629317482044e-11\nWORD_ROW -> οὐρανοῦ NOUN     prob -> 3.8907387808589985e-15\nWORD_ROW -> πεσὼν VERB     prob -> 7.079774556289554e-19\nWORD_ROW -> ἔκυσε VERB     prob -> 1.2405888449107333e-20\nWORD_ROW -> γαῖαν NOUN     prob -> 4.201391041818403e-24\nWORD_ROW -> · PUNCT     prob -> 2.159651365370989e-25\n==================== new sentence ================================== \nWORD_ROW -> ἡ DET     prob -> 0.001159083620643415\nWORD_ROW -> δὲ ADV     prob -> 8.253770887294058e-06\nWORD_ROW -> τίκτεται VERB     prob -> 2.9834479225555876e-07\nWORD_ROW -> βροτοῖς NOUN     prob -> 1.418069320134682e-11\nWORD_ROW -> μήλων NOUN     prob -> 3.0330061058590046e-16\nWORD_ROW -> τε PART     prob -> 1.7757882917639428e-18\nWORD_ROW -> βοσκὰς NOUN     prob -> 3.338161676622189e-20\nWORD_ROW -> καὶ CCONJ     prob -> 6.559543741822298e-22\nWORD_ROW -> βίον NOUN     prob -> 1.2230251804528385e-25\nWORD_ROW -> Δημήτριον ADJ     prob -> 5.676678192589731e-27\nWORD_ROW -> · PUNCT     prob -> 2.236766559865016e-28\n==================== new sentence ================================== \nWORD_ROW -> δενδρῶτις NOUN     prob -> 0.009083712380415677\nWORD_ROW -> ὥρα NOUN     prob -> 9.077618147960047e-05\nWORD_ROW -> δ̓ PART     prob -> 1.643219632915586e-06\nWORD_ROW -> ἐκ ADP     prob -> 6.42964979680728e-09\nWORD_ROW -> νοτίζοντος VERB     prob -> 1.673532378767863e-11\nWORD_ROW -> γάμου NOUN     prob -> 6.952696333580202e-16\nWORD_ROW -> τέλειος ADJ     prob -> 2.4203234091582504e-17\nWORD_ROW -> ἐστί VERB     prob -> 6.7417702411145565e-21\nWORD_ROW -> . PUNCT     prob -> 5.747480071140613e-22\n==================== new sentence ================================== \nWORD_ROW -> ἐν ADP     prob -> 0.005688856024066014\nWORD_ROW -> Ἱππολύτῳ NOUN     prob -> 0.00017341093921177179\nWORD_ROW -> Εὐριπιδείῳ ADJ     prob -> 4.829327045983555e-06\nWORD_ROW -> πάλιν ADV     prob -> 1.0040897909912665e-09\nWORD_ROW -> ἡ DET     prob -> 1.104378526327329e-12\nWORD_ROW -> Ἀφροδίτη NOUN     prob -> 3.7034840512811114e-16\nWORD_ROW -> φησίν VERB     prob -> 9.922434151649288e-20\nWORD_ROW -> · PUNCT     prob -> 7.00435519445342e-21\n"
     ]
    }
   ],
   "source": [
    "print(\"==================== TEST ON GREEK ================================== \")\n",
    "\n",
    "for i in range(0,5):\n",
    "    print(\"==================== new sentence ================================== \")\n",
    "    backtrace_greek, probabilities_greek = viterbi(sentences_greek[i], tagset_greek, probEmission_greek, probTransition_greek, 0, statistics_greek);\n",
    "    printPosTag(sentences_greek[i], tagset_greek, backtrace_greek, probabilities_greek);"
   ]
  },
  {
   "source": [
    "TRAIN AND DECODING LATIN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences_latin, tagset_latin, probEmission_latin, probTransition_latin, statistics_latin = train(\"latin\",True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== TEST ON LATIN ================================== \nWORD_ROW -> + PUNCT     prob -> 0.0477907757517123\nWORD_ROW -> In ADP     prob -> 7.95175730713278e-05\nWORD_ROW -> Dei PROPN     prob -> 6.730600719867964e-07\nWORD_ROW -> nomine NOUN     prob -> 3.957304376743928e-09\nWORD_ROW -> regnante VERB     prob -> 9.154634916135536e-12\nWORD_ROW -> domno NOUN     prob -> 1.1573354564099308e-14\nWORD_ROW -> nostro DET     prob -> 6.188509865711393e-17\nWORD_ROW -> Carulo PROPN     prob -> 5.469200602474012e-20\nWORD_ROW -> rege NOUN     prob -> 7.500897305500222e-23\nWORD_ROW -> Francorum NOUN     prob -> 2.1081007115471513e-26\nWORD_ROW -> et CCONJ     prob -> 1.0864475686704603e-27\nWORD_ROW -> Langobardorum NOUN     prob -> 6.444268799442303e-31\nWORD_ROW -> , PUNCT     prob -> 7.124095018424678e-32\nWORD_ROW -> anno NOUN     prob -> 2.2636869354322035e-34\nWORD_ROW -> regni NOUN     prob -> 1.101864558019235e-37\nWORD_ROW -> eius DET     prob -> 9.125503370060112e-40\nWORD_ROW -> quo PRON     prob -> 2.715982358959434e-43\nWORD_ROW -> coepit VERB     prob -> 7.647381412813452e-46\nWORD_ROW -> Langobardiam PROPN     prob -> 3.088599714272366e-49\nWORD_ROW -> primo ADJ     prob -> 5.578698803762913e-53\nWORD_ROW -> , PUNCT     prob -> 8.662360161268154e-54\nWORD_ROW -> septimo ADJ     prob -> 1.8957266751513478e-57\nWORD_ROW -> decimo ADJ     prob -> 2.8599079029877134e-60\nWORD_ROW -> kalendas NOUN     prob -> 4.1892451749678444e-63\nWORD_ROW -> augustas ADJ     prob -> 8.526477951212123e-67\nWORD_ROW -> , PUNCT     prob -> 1.3239543040160543e-67\nWORD_ROW -> per ADP     prob -> 9.932302604830745e-70\nWORD_ROW -> indictionem NOUN     prob -> 2.2108901212841838e-72\nWORD_ROW -> duodecimam ADJ     prob -> 7.998938089017041e-76\nWORD_ROW -> . PUNCT     prob -> 4.518158510355026e-77\n"
     ]
    }
   ],
   "source": [
    "print(\"==================== TEST ON LATIN ================================== \")\n",
    "backtrace_latin, probabilities_latin = viterbi(sentences_latin[0], tagset_latin, probEmission_latin, probTransition_latin, 4, statistics_latin);\n",
    "printPosTag(sentences_latin[0], tagset_latin, backtrace_latin, probabilities_latin);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAccuracy(language, tagset, probEmission, probTransition, smoothingType, statistics):\n",
    "    sentences_test = readFile(language,\"test\");\n",
    "    count_tag_correct = 0;\n",
    "    count_total_tag = 0;\n",
    "    for sentence in sentences_test:\n",
    "        backtrace_test, probabilities_test = viterbi(sentence, tagset, probEmission, probTransition, smoothingType, statistics);\n",
    "         #Get real tag\n",
    "        i = 0;\n",
    "        for token in sentence:\n",
    "            real_tag = token[\"upos\"];\n",
    "            if tagset.index(real_tag) == backtrace_test[i]:\n",
    "                count_tag_correct = count_tag_correct + 1;\n",
    "            count_total_tag = count_total_tag + 1;\n",
    "            i = i + 1;\n",
    "    return count_tag_correct/count_total_tag;"
   ]
  },
  {
   "source": [
    "CALCULATE ACCURACY ON TEST SET OF GREEK"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ACCURACY GREEK  0.20745264564149052\n"
     ]
    }
   ],
   "source": [
    "accuracy_greek = calculateAccuracy(\"greek\", tagset_greek, probEmission_greek, probTransition_greek, 1, statistics_greek);\n",
    "print(\"ACCURACY GREEK  \" + str(accuracy_greek))\n"
   ]
  },
  {
   "source": [
    "CALCULATE ACCURACY ON TEST SET OF LATIN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ACCURACY LATIN 0.9436023090659911\n"
     ]
    }
   ],
   "source": [
    "accuracy_latin = calculateAccuracy(\"latin\", tagset_latin, probEmission_latin, probTransition_latin, 4, statistics_latin);\n",
    "print(\"ACCURACY LATIN \" + str(accuracy_latin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}