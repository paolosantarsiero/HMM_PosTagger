{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from conllu import parse\n",
    "import math"
   ]
  },
  {
   "source": [
    "INIT TAG SETS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_g = ['ADJ','ADP','ADV','CCONJ','DET','INTJ','NOUN','NUM','PART','PRON','PUNCT','SCONJ','VERB','X'];\n",
    "tags_l = ['ADJ','ADP','ADV','AUX','CCONJ','DET','NOUN','NUM','PART','PRON','PROPN','PUNCT','SCONJ','VERB','X'];"
   ]
  },
  {
   "source": [
    "COUNTING TAG AND WORD'S TAG"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(word, tag, tagset, count_words, count_tag):\n",
    "    index_of_tag = tagset.index(tag);\n",
    "    totIndex = len(tagset);\n",
    "    # update count of tag\n",
    "    count_tag[index_of_tag] = count_tag[index_of_tag] + 1;\n",
    "    # update count of word\n",
    "    if(word in count_words.keys()):\n",
    "        count_words[word][index_of_tag] = count_words[word][index_of_tag] + 1;\n",
    "    else:\n",
    "        word_row = np.zeros(len(tagset) + 1, dtype=int);\n",
    "        word_row[index_of_tag] = 1;\n",
    "        count_words[word] = word_row;\n",
    "    # update total count of word\n",
    "    count_words[word][totIndex] = count_words[word][totIndex] + 1;\n",
    "    # update total count of tag\n",
    "    count_tag[totIndex] = count_tag[totIndex] + 1;\n",
    "    return count_words, count_tag;"
   ]
  },
  {
   "source": [
    "CALCULATE EMISSION PROBABILITY"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateEmissionProbability(word, tag, tagset, count_words, count_tag ,probEmission):\n",
    "    index_of_tag = tagset.index(tag);\n",
    "    # index for total count\n",
    "    totIndex = len(tagset);\n",
    "    #if word exist then update count\n",
    "    if(word in probEmission.keys()):\n",
    "        probEmission[word][index_of_tag] = count_words[word][index_of_tag] / count_tag[index_of_tag];\n",
    "    #if NTOT word exist then create row\n",
    "    else:\n",
    "        prob_row = np.zeros(len(tagset) + 1);\n",
    "        prob_row[index_of_tag] = count_words[word][index_of_tag] / count_tag[index_of_tag];\n",
    "        probEmission[word] = prob_row;\n",
    "    return probEmission;"
   ]
  },
  {
   "source": [
    "CALCULATE TRANSITION PROBABILITY"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateTransictionProbability(word, prev_tag, tag, tagset, transition, count_tag, nSentences, probTransition):\n",
    "    #natural sequence when scan senteces\n",
    "    trans_tag = \"%s_%s\" % (prev_tag,tag);\n",
    "    #Sequence used to saved\n",
    "    trans_tag_real = \"%s_%s\" % (tag,prev_tag);\n",
    "    \n",
    "    if(trans_tag in transition.keys()):\n",
    "        transition[trans_tag] = transition[trans_tag] + 1;\n",
    "    else:\n",
    "        transition[trans_tag] = 1;\n",
    "\n",
    "    #When tag is Q0 (start) the calculate probTransistion with number of sentences\n",
    "    #Else use normal Transition probability\n",
    "    if(trans_tag in probTransition.keys() and prev_tag != 'Q0'):\n",
    "        index_of_tag = tagset.index(prev_tag);\n",
    "        probTransition[trans_tag_real] = transition[trans_tag] /count_tag[index_of_tag];\n",
    "    else:\n",
    "        probTransition[trans_tag_real] = transition[trans_tag]/ nSentences;\n",
    "\n",
    "    return tag, probTransition;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(language,fileType):\n",
    "    nameFile = \"./corpus/%s/data_%s.conllu\" % (language,fileType);\n",
    "    tsv_file = open(nameFile,\"r\",encoding=\"utf-8\").read();\n",
    "    sentences = parse(tsv_file)\n",
    "    return sentences;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(language):\n",
    "    #select tag sets of language choosen\n",
    "    if language == \"greek\":\n",
    "        tagset = tags_g;\n",
    "    elif language == \"latin\":\n",
    "        tagset = tags_l;\n",
    "    else:\n",
    "        raise Exception(\"Language not found!\");\n",
    "\n",
    "    # INIT DATA STRUCTURE\n",
    "    count_words = dict();\n",
    "    count_tag = np.zeros(len(tagset) + 1, dtype = int);\n",
    "    probEmission = dict();\n",
    "    probTransition = dict();\n",
    "    transition = dict();\n",
    "\n",
    "    #Count number of sentence for calculate probTransistio with tag start Q0\n",
    "    nSentences = 0;\n",
    "\n",
    "    sentences = readFile(language,\"train\")\n",
    "    for sentence in sentences:\n",
    "        prev_tag = 'Q0';\n",
    "        nSentences = nSentences + 1;\n",
    "        for token in sentence:\n",
    "            word = token[\"form\"];\n",
    "            tag = token[\"upos\"];\n",
    "            count_words, count_tag = count(word, tag, tagset, count_words, count_tag);\n",
    "            probEmission = calculateEmissionProbability(word,tag,tagset, count_words, count_tag, probEmission);\n",
    "            prev_tag, probTransition = calculateTransictionProbability(word, prev_tag, tag, tagset, transition, count_tag, nSentences, probTransition)\n",
    "    return sentences,tagset, probEmission, probTransition;"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence(sentence):\n",
    "    words = [];\n",
    "    for token in sentence:\n",
    "        words.append(token[\"form\"]);\n",
    "    return words"
   ]
  },
  {
   "source": [
    "IMPLEMENT SMOOTHING"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectSmoothing(type, probEmission, word, index_of_tag, tagset):\n",
    "    probE = 0;\n",
    "    # NO SMOOTHING\n",
    "    if type == False and word in probEmission.keys():\n",
    "       probE = probEmission[word][index_of_tag]\n",
    "    # IF WORD NOT EXIST THEN SET NOUN PROBABILITY 1\n",
    "    elif type == 0 and word not in probEmission.keys():\n",
    "        prob_row = np.zeros(len(tagset) + 1);\n",
    "        index_of_noun = tagset.index(\"NOUN\");\n",
    "        prob_row[index_of_noun] = 1;\n",
    "        probE = prob_row;\n",
    "    elif type == 1 and word not in probEmission.keys():\n",
    "        prob_row = np.zeros(len(tagset) + 1);\n",
    "        index_of_noun = tagset.index(\"NOUN\");\n",
    "        index_of_verb = tagset.index(\"VERB\");\n",
    "        prob_row[index_of_noun] = 0.5;\n",
    "        prob_row[index_of_verb] = 0.5;\n",
    "        probE = prob_row;\n",
    "    elif type == 2 and word not in probEmission.keys():\n",
    "        unk_prob = 1 / len(tagset);\n",
    "        prob_row = np.full(len(tagset) + 1, unk_prob);\n",
    "        probE = prob_row;\n",
    "    return probE;"
   ]
  },
  {
   "source": [
    "DECODING WITH VITERBI"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def viterbi(sentence, tagset, probEmission, probTransition,smoothingType):\n",
    "    words = tokenize_sentence(sentence);\n",
    "    start_tag = \"Q0\";\n",
    "    viterbi_matrix = np.zeros((len(tagset),len(words)));\n",
    "    backtrace = np.zeros(len(words), dtype = int);\n",
    "    probabilites = np.zeros(len(words));\n",
    "    t = 0;\n",
    "   \n",
    "    for word in words:\n",
    "        # Calculate viterbi column for every tag possible\n",
    "        for tag in tagset:\n",
    "            index_of_tag = tagset.index(tag);\n",
    "            #Get Emission probabilty of word ( HERE WHEN CAN APPLY SMOOTHING)\n",
    "            \n",
    "            probE = selectSmoothing(smoothingType, probEmission, word, index_of_tag, tagset);\n",
    "            #Run first iteration of viterbi to initialize first column\n",
    "            if t == 0:\n",
    "                tran_tag = \"%s_%s\" % (tag,start_tag);   \n",
    "                probT = 0\n",
    "                if tran_tag in probTransition.keys():\n",
    "                    probT = probTransition[tran_tag];\n",
    "                viterbi_matrix[index_of_tag][t] = probE * probT;\n",
    "            else:\n",
    "                max_tmp = np.zeros(len(tagset));\n",
    "                for i in range(0,len(tagset)):\n",
    "                    tran_tag = \"%s_%s\" % (tag,tagset[i]);\n",
    "                    probT = 0\n",
    "                    if tran_tag in probTransition.keys():\n",
    "                        probT = probTransition[tran_tag];\n",
    "\n",
    "                    max_tmp[i] = viterbi_matrix[i,t-1] * probT;\n",
    "                viterbi_matrix[index_of_tag,t] = np.amax(max_tmp) * probE;\n",
    "\n",
    "        index_max_values = np.argmax(viterbi_matrix[:,t]);  \n",
    "        backtrace[t] = index_max_values;\n",
    "        probabilites[t] = viterbi_matrix[index_max_values,t];\n",
    "        t= t +1;\n",
    "    return backtrace,probabilites;"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printPosTag(sentence, tagset, backtrace , probabilities):\n",
    "    i = 0;\n",
    "    words = tokenize_sentence(sentence);\n",
    "    for word in words:\n",
    "        print(\"WORD -> \" + word + \" , TAG -> \" + tagset[backtrace[i]] + \" , WITH PROB -> \" + str(probabilities[i]))\n",
    "        i = i + 1;"
   ]
  },
  {
   "source": [
    "TRAIN AND DECODING GREEK"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences_greek, tagset_greek, probEmission_greek, probTransition_greek =  train(\"greek\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== TEST ON GREEK ================================== \n==================== new sentence ================================== \nWORD -> ἐρᾷ , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> μὲν , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> ἁγνὸς , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> οὐρανὸς , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> τρῶσαι , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> χθόνα , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> , , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> ἔρως , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> δὲ , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> γαῖαν , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> λαμβάνει , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> γάμου , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> τυχεῖν , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> · , TAG -> ADJ , WITH PROB -> 0.0\n==================== new sentence ================================== \nWORD -> ὄμβρος , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> δ̓ , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> ἀπ̓ , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> εὐνάοντος , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> οὐρανοῦ , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> πεσὼν , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> ἔκυσε , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> γαῖαν , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> · , TAG -> ADJ , WITH PROB -> 0.0\n==================== new sentence ================================== \nWORD -> ἡ , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> δὲ , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> τίκτεται , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> βροτοῖς , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> μήλων , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> τε , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> βοσκὰς , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> καὶ , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> βίον , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> Δημήτριον , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> · , TAG -> ADJ , WITH PROB -> 0.0\n==================== new sentence ================================== \nWORD -> δενδρῶτις , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> ὥρα , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> δ̓ , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> ἐκ , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> νοτίζοντος , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> γάμου , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> τέλειος , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> ἐστί , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> . , TAG -> ADJ , WITH PROB -> 0.0\n==================== new sentence ================================== \nWORD -> ἐν , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> Ἱππολύτῳ , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> Εὐριπιδείῳ , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> πάλιν , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> ἡ , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> Ἀφροδίτη , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> φησίν , TAG -> ADJ , WITH PROB -> 0.0\nWORD -> · , TAG -> ADJ , WITH PROB -> 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"==================== TEST ON GREEK ================================== \")\n",
    "\n",
    "for i in range(0,5):\n",
    "    print(\"==================== new sentence ================================== \")\n",
    "    backtrace_greek, probabilities_greek = viterbi(sentences_greek[i], tagset_greek, probEmission_greek, probTransition_greek, 2);\n",
    "    printPosTag(sentences_greek[i], tagset_greek, backtrace_greek, probabilities_greek);"
   ]
  },
  {
   "source": [
    "TRAIN AND DECODING LATIN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences_latin, tagset_latin, probEmission_latin, probTransition_latin =  train(\"latin\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== TEST ON LATIN ================================== \nWORD -> + , TAG -> PUNCT , WITH PROB -> 0.0477907757517123\nWORD -> In , TAG -> ADP , WITH PROB -> 7.95175730713278e-05\nWORD -> Dei , TAG -> PROPN , WITH PROB -> 6.730600719867964e-07\nWORD -> nomine , TAG -> NOUN , WITH PROB -> 3.957304376743928e-09\nWORD -> regnante , TAG -> VERB , WITH PROB -> 9.154634916135536e-12\nWORD -> domno , TAG -> NOUN , WITH PROB -> 1.1573354564099308e-14\nWORD -> nostro , TAG -> DET , WITH PROB -> 6.188509865711393e-17\nWORD -> Carulo , TAG -> PROPN , WITH PROB -> 5.469200602474012e-20\nWORD -> rege , TAG -> NOUN , WITH PROB -> 7.500897305500222e-23\nWORD -> Francorum , TAG -> NOUN , WITH PROB -> 2.1081007115471513e-26\nWORD -> et , TAG -> CCONJ , WITH PROB -> 1.0864475686704603e-27\nWORD -> Langobardorum , TAG -> NOUN , WITH PROB -> 6.444268799442303e-31\nWORD -> , , TAG -> PUNCT , WITH PROB -> 7.124095018424678e-32\nWORD -> anno , TAG -> NOUN , WITH PROB -> 2.2636869354322035e-34\nWORD -> regni , TAG -> NOUN , WITH PROB -> 1.101864558019235e-37\nWORD -> eius , TAG -> DET , WITH PROB -> 9.125503370060112e-40\nWORD -> quo , TAG -> PRON , WITH PROB -> 2.715982358959434e-43\nWORD -> coepit , TAG -> VERB , WITH PROB -> 7.647381412813452e-46\nWORD -> Langobardiam , TAG -> PROPN , WITH PROB -> 3.088599714272366e-49\nWORD -> primo , TAG -> ADJ , WITH PROB -> 5.578698803762913e-53\nWORD -> , , TAG -> PUNCT , WITH PROB -> 8.662360161268154e-54\nWORD -> septimo , TAG -> ADJ , WITH PROB -> 1.8957266751513478e-57\nWORD -> decimo , TAG -> ADJ , WITH PROB -> 2.8599079029877134e-60\nWORD -> kalendas , TAG -> NOUN , WITH PROB -> 4.1892451749678444e-63\nWORD -> augustas , TAG -> ADJ , WITH PROB -> 8.526477951212123e-67\nWORD -> , , TAG -> PUNCT , WITH PROB -> 1.3239543040160543e-67\nWORD -> per , TAG -> ADP , WITH PROB -> 9.932302604830745e-70\nWORD -> indictionem , TAG -> NOUN , WITH PROB -> 2.2108901212841838e-72\nWORD -> duodecimam , TAG -> ADJ , WITH PROB -> 7.998938089017041e-76\nWORD -> . , TAG -> PUNCT , WITH PROB -> 4.518158510355026e-77\n"
     ]
    }
   ],
   "source": [
    "print(\"==================== TEST ON LATIN ================================== \")\n",
    "backtrace_latin, probabilities_latin = viterbi(sentences_latin[0], tagset_latin, probEmission_latin, probTransition_latin);\n",
    "printPosTag(sentences_latin[0], tagset_latin, backtrace_latin, probabilities_latin);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'ζῶσι'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-419c522b7c91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentences_greek_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"greek\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences_greek_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbacktrace_greek_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilities_greek_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mviterbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset_greek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobEmission_greek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobTransition_greek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprintPosTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_greek\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset_greek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbacktrace_greek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilities_greek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-10f498073b1d>\u001b[0m in \u001b[0;36mviterbi\u001b[0;34m(sentence, tagset, probEmission, probTransition)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mindex_of_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m#Get Emission probabilty of word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mprobE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobEmission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_of_tag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;31m#Run first iteration of viterbi to initialize first column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ζῶσι'"
     ]
    }
   ],
   "source": [
    "sentences_greek_test = readFile(\"greek\",\"test\");\n",
    "for sentence in sentences_greek_test:\n",
    "    backtrace_greek_test, probabilities_greek_test = viterbi(sentence, tagset_greek, probEmission_greek, probTransition_greek);\n",
    "    printPosTag(sentences_greek[i], tagset_greek, backtrace_greek, probabilities_greek);"
   ]
  },
  {
   "source": [
    "SMOOTHING"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}