{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from conllu import parse\n",
    "import math"
   ]
  },
  {
   "source": [
    "INIT TAG SETS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_g = ['ADJ','ADP','ADV','CCONJ','DET','INTJ','NOUN','NUM','PART','PRON','PUNCT','SCONJ','VERB','X'];\n",
    "tags_l = ['ADJ','ADP','ADV','AUX','CCONJ','DET','NOUN','NUM','PART','PRON','PROPN','PUNCT','SCONJ','VERB','X'];"
   ]
  },
  {
   "source": [
    "COUNTING TAG AND WORD'S TAG"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(word, tag, tagset, count_words, count_tag):\n",
    "    index_of_tag = tagset.index(tag);\n",
    "    totIndex = len(tagset);\n",
    "    # update count of tag\n",
    "    count_tag[index_of_tag] = count_tag[index_of_tag] + 1;\n",
    "    # update count of word\n",
    "    if(word in count_words.keys()):\n",
    "        count_words[word][index_of_tag] = count_words[word][index_of_tag] + 1;\n",
    "    else:\n",
    "        word_row = np.zeros(len(tagset) + 1, dtype=int);\n",
    "        word_row[index_of_tag] = 1;\n",
    "        count_words[word] = word_row;\n",
    "    # update total count of word\n",
    "    count_words[word][totIndex] = count_words[word][totIndex] + 1;\n",
    "    # update total count of tag\n",
    "    count_tag[totIndex] = count_tag[totIndex] + 1;\n",
    "    return count_words, count_tag;"
   ]
  },
  {
   "source": [
    "CALCULATE EMISSION PROBABILITY"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateEmissionProbability(word, tag, tagset, count_words, count_tag ,probEmission):\n",
    "    index_of_tag = tagset.index(tag);\n",
    "    # index for total count\n",
    "    totIndex = len(tagset);\n",
    "    #if word exist then update count\n",
    "    if(word in probEmission.keys()):\n",
    "        probEmission[word][index_of_tag] = count_words[word][index_of_tag] / count_tag[index_of_tag];\n",
    "\n",
    "    #if NTOT word exist then create row\n",
    "    else:\n",
    "        prob_row = np.zeros(len(tagset) + 1);\n",
    "        prob_row[index_of_tag] = count_words[word][index_of_tag] / count_tag[index_of_tag];\n",
    "        probEmission[word] = prob_row;\n",
    "    return probEmission;"
   ]
  },
  {
   "source": [
    "CALCULATE TRANSITION PROBABILITY"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateTransictionProbability(word, prev_tag, tag, tagset, transition, count_tag, nSentences, probTransition):\n",
    "    #natural sequence when scan senteces\n",
    "    trans_tag = \"%s_%s\" % (prev_tag,tag);\n",
    "    #Sequence used to saved\n",
    "    trans_tag_real = \"%s_%s\" % (tag,prev_tag);\n",
    "    \n",
    "    if(trans_tag in transition.keys()):\n",
    "        transition[trans_tag] = transition[trans_tag] + 1;\n",
    "    else:\n",
    "        transition[trans_tag] = 1;\n",
    "\n",
    "    #When tag is Q0 (start) the calculate probTransistion with number of sentences\n",
    "    #Else use normal Transition probability\n",
    "    if(trans_tag in probTransition.keys() and prev_tag != 'Q0'):\n",
    "        index_of_tag = tagset.index(prev_tag);\n",
    "        probTransition[trans_tag_real] = transition[trans_tag] /count_tag[index_of_tag];\n",
    "    else:\n",
    "        probTransition[trans_tag_real] = transition[trans_tag]/ nSentences;\n",
    "\n",
    "    return tag, probTransition;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(language,fileType):\n",
    "    nameFile = \"./corpus/%s/data_%s.conllu\" % (language,fileType);\n",
    "    tsv_file = open(nameFile,\"r\",encoding=\"utf-8\").read();\n",
    "    sentences = parse(tsv_file)\n",
    "    return sentences;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(language,statisticsIsEnabled):\n",
    "    #select tag sets of language choosen\n",
    "    if language == \"greek\":\n",
    "        tagset = tags_g;\n",
    "    elif language == \"latin\":\n",
    "        tagset = tags_l;\n",
    "    else:\n",
    "        raise Exception(\"Language not found!\");\n",
    "\n",
    "    # INIT DATA STRUCTURE\n",
    "    count_words = dict();\n",
    "    count_tag = np.zeros(len(tagset) + 1, dtype = int);\n",
    "    probEmission = dict();\n",
    "    probTransition = dict();\n",
    "    transition = dict();\n",
    "    statistics = np.zeros(len(tagset));\n",
    "\n",
    "    if statisticsIsEnabled == True:\n",
    "        statistics = calculateStatisticPosTagging(language)\n",
    "\n",
    "    #Count number of sentence for calculate probTransistio with tag start Q0\n",
    "    nSentences = 0;\n",
    "\n",
    "    sentences = readFile(language,\"train\")\n",
    "    for sentence in sentences:\n",
    "        prev_tag = 'Q0';\n",
    "        nSentences = nSentences + 1;\n",
    "        for token in sentence:\n",
    "            word = token[\"form\"];\n",
    "            tag = token[\"upos\"];\n",
    "            count_words, count_tag = count(word, tag, tagset, count_words, count_tag);\n",
    "            probEmission = calculateEmissionProbability(word,tag,tagset, count_words, count_tag, probEmission);\n",
    "            prev_tag, probTransition = calculateTransictionProbability(word, prev_tag, tag, tagset, transition, count_tag, nSentences, probTransition)\n",
    "    return sentences,tagset, probEmission, probTransition,statistics;"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence(sentence):\n",
    "    words = [];\n",
    "    for token in sentence:\n",
    "        words.append(token[\"form\"]);\n",
    "    return words"
   ]
  },
  {
   "source": [
    "CALCULATE STATISTIC POS TAGGIN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateStatisticPosTagging(language):\n",
    "    #select tag sets of language choosen\n",
    "    if language == \"greek\":\n",
    "        tagset = tags_g;\n",
    "    elif language == \"latin\":\n",
    "        tagset = tags_l;\n",
    "    else:\n",
    "        raise Exception(\"Language not found!\");\n",
    "\n",
    "    count_words = dict();\n",
    "    count_tag = np.zeros(len(tagset) + 1, dtype = int);\n",
    "    count_tag_one_occured = np.zeros(len(tagset), dtype = int);\n",
    "    count_tag_one_occured_total = 0;\n",
    "\n",
    "    statistics = np.zeros(len(tagset));\n",
    "    \n",
    "\n",
    "    sentences = readFile(language,\"dev\");\n",
    "    for sentence in sentences:\n",
    "        for token in sentence:\n",
    "            word = token[\"form\"];\n",
    "            tag = token[\"upos\"];\n",
    "            count_words, count_tag = count(word, tag, tagset, count_words, count_tag);\n",
    "\n",
    "    totIndex = len(tagset);\n",
    "    for word in count_words:\n",
    "        if count_words[word][totIndex] == 1:\n",
    "            index_of_tag = np.argmax(count_words[word]);\n",
    "            count_tag_one_occured[index_of_tag] = count_tag_one_occured[index_of_tag] + 1;\n",
    "            count_tag_one_occured_total =  count_tag_one_occured_total + 1;\n",
    "\n",
    "    for tag in tagset:\n",
    "        index_of_tag = tagset.index(tag);\n",
    "        statistics[index_of_tag] = count_tag_one_occured[index_of_tag] / count_tag_one_occured_total;\n",
    "    return statistics;"
   ]
  },
  {
   "source": [
    "IMPLEMENT SMOOTHING"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectSmoothing(type, probEmission, word, index_of_tag, tagset, statistics):\n",
    "    # NO SMOOTHING\n",
    "    if word in probEmission.keys():\n",
    "       return probEmission[word][index_of_tag]\n",
    "    elif type == 0 and word not in probEmission.keys():\n",
    "        return 0.00001;\n",
    "    # IF WORD NOT EXIST THEN SET NOUN PROBABILITY 1\n",
    "    elif type == 1 and word not in probEmission.keys():\n",
    "        prob_row = np.zeros(len(tagset) + 1);\n",
    "        index_of_noun = tagset.index(\"NOUN\");\n",
    "        prob_row[index_of_noun] = 1;\n",
    "        return prob_row[index_of_tag];\n",
    "    elif type == 2 and word not in probEmission.keys():\n",
    "        prob_row = np.zeros(len(tagset) + 1);\n",
    "        index_of_noun = tagset.index(\"NOUN\");\n",
    "        index_of_verb = tagset.index(\"VERB\");\n",
    "        prob_row[index_of_noun] = 0.5;\n",
    "        prob_row[index_of_verb] = 0.5;\n",
    "        return prob_row[index_of_tag];\n",
    "    elif type == 3 and word not in probEmission.keys():\n",
    "        unk_prob = 1 / len(tagset);\n",
    "        prob_row = np.full(len(tagset) + 1, unk_prob);\n",
    "        return prob_row[index_of_tag];\n",
    "    elif type == 4 and word not in probEmission.keys():\n",
    "        return statistics[index_of_tag];\n",
    "    else:\n",
    "        return 0.00001;"
   ]
  },
  {
   "source": [
    "DECODING WITH VITERBI"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def viterbi(sentence, tagset, probEmission, probTransition, smoothingType, statistics):\n",
    "    words = tokenize_sentence(sentence);\n",
    "    start_tag = \"Q0\";\n",
    "    viterbi_matrix = np.zeros((len(tagset),len(words)));\n",
    "    backtrace = np.zeros(len(words), dtype = int);\n",
    "    probabilites = np.zeros(len(words));\n",
    "    t = 0;\n",
    "   \n",
    "    for word in words:\n",
    "        # Calculate viterbi column for every tag possible\n",
    "        for tag in tagset:\n",
    "            index_of_tag = tagset.index(tag);\n",
    "            #Get Emission probabilty of word ( HERE WHEN CAN APPLY SMOOTHING)\n",
    "            probE = selectSmoothing(smoothingType, probEmission, word, index_of_tag, tagset, statistics);\n",
    "\n",
    "            if probE == 0:\n",
    "                probE = np.log(0.00001)\n",
    "            else:\n",
    "                probE = np.log(probE)\n",
    "\n",
    "            #Run first iteration of viterbi to initialize first column\n",
    "            if t == 0:\n",
    "                tran_tag = \"%s_%s\" % (tag,start_tag);   \n",
    "                probT = np.log(0.00001);\n",
    "                if tran_tag in probTransition.keys():\n",
    "                    probT = np.log(probTransition[tran_tag]);\n",
    "                viterbi_matrix[index_of_tag][t] = probE + probT;\n",
    "            else:\n",
    "                max_tmp = np.zeros(len(tagset));\n",
    "                for i in range(0,len(tagset)):\n",
    "                    tran_tag = \"%s_%s\" % (tag,tagset[i]);\n",
    "                    probT = np.log(0.00001);\n",
    "                    if tran_tag in probTransition.keys():\n",
    "                        probT = np.log(probTransition[tran_tag]);\n",
    "\n",
    "                    max_tmp[i] = viterbi_matrix[i,t-1] + probT;\n",
    "                viterbi_matrix[index_of_tag,t] = np.amax(max_tmp) + probE;\n",
    "\n",
    "        index_max_values = np.argmax(viterbi_matrix[:,t]);  \n",
    "        backtrace[t] = index_max_values;\n",
    "        probabilites[t] = viterbi_matrix[index_max_values,t];\n",
    "        t= t +1;\n",
    "    return backtrace,probabilites;"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printPosTag(sentence, tagset, backtrace , probabilities):\n",
    "    i = 0;\n",
    "    words = tokenize_sentence(sentence);\n",
    "    for word in words:\n",
    "        print(\"WORD_ROW -> \" + word + \" \" + tagset[backtrace[i]] + \"     prob -> \" + str(probabilities[i]))\n",
    "        i = i + 1;"
   ]
  },
  {
   "source": [
    "TRAIN AND DECODING GREEK"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences_greek, tagset_greek, probEmission_greek, probTransition_greek, statistics_greek  =  train(\"greek\",False);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== TEST ON GREEK ================================== \n==================== new sentence ================================== \nWORD_ROW -> ἐρᾷ VERB     prob -> -9.268481272273874\nWORD_ROW -> μὲν PART     prob -> -15.012261505759101\nWORD_ROW -> ἁγνὸς ADJ     prob -> -25.780646354223645\nWORD_ROW -> οὐρανὸς NOUN     prob -> -35.304979691779565\nWORD_ROW -> τρῶσαι VERB     prob -> -37.33968533961801\nWORD_ROW -> χθόνα NOUN     prob -> -46.42668418324466\nWORD_ROW -> , PUNCT     prob -> -48.80483279303211\nWORD_ROW -> ἔρως NOUN     prob -> -59.96014696849298\nWORD_ROW -> δὲ PART     prob -> -64.59106304839658\nWORD_ROW -> γαῖαν NOUN     prob -> -72.5121179919485\nWORD_ROW -> λαμβάνει VERB     prob -> -74.95228874789511\nWORD_ROW -> γάμου NOUN     prob -> -85.04102125627635\nWORD_ROW -> τυχεῖν VERB     prob -> -94.40983865023648\nWORD_ROW -> · PUNCT     prob -> -97.06068988639385\n==================== new sentence ================================== \nWORD_ROW -> ὄμβρος NOUN     prob -> -10.573245640015733\nWORD_ROW -> δ̓ PART     prob -> -14.584985064607213\nWORD_ROW -> ἀπ̓ ADP     prob -> -21.619237189318902\nWORD_ROW -> εὐνάοντος ADJ     prob -> -24.24777411009604\nWORD_ROW -> οὐρανοῦ NOUN     prob -> -33.18017733735385\nWORD_ROW -> πεσὼν VERB     prob -> -41.791874702020195\nWORD_ROW -> ἔκυσε VERB     prob -> -45.836115718053364\nWORD_ROW -> γαῖαν NOUN     prob -> -53.82662656096957\nWORD_ROW -> · PUNCT     prob -> -56.794680521103075\n==================== new sentence ================================== \nWORD_ROW -> ἡ DET     prob -> -6.76012556826819\nWORD_ROW -> δὲ ADV     prob -> -11.704840384797905\nWORD_ROW -> τίκτεται VERB     prob -> -15.025015998282134\nWORD_ROW -> βροτοῖς NOUN     prob -> -24.979139710169875\nWORD_ROW -> μήλων NOUN     prob -> -35.73180724605854\nWORD_ROW -> τε PART     prob -> -40.872287241516204\nWORD_ROW -> βοσκὰς NOUN     prob -> -44.84628160063681\nWORD_ROW -> καὶ CCONJ     prob -> -48.7759509968833\nWORD_ROW -> βίον NOUN     prob -> -57.363299879271516\nWORD_ROW -> Δημήτριον ADJ     prob -> -60.43343127443144\nWORD_ROW -> · PUNCT     prob -> -63.66735128087649\n==================== new sentence ================================== \nWORD_ROW -> δενδρῶτις NOUN     prob -> -4.7012723174576445\nWORD_ROW -> ὥρα NOUN     prob -> -9.307113625275147\nWORD_ROW -> δ̓ PART     prob -> -13.318853049866627\nWORD_ROW -> ἐκ ADP     prob -> -18.8623457641292\nWORD_ROW -> νοτίζοντος VERB     prob -> -24.81349943351824\nWORD_ROW -> γάμου NOUN     prob -> -34.90223194189948\nWORD_ROW -> τέλειος ADJ     prob -> -38.260045409511186\nWORD_ROW -> ἐστί VERB     prob -> -46.4459644153868\nWORD_ROW -> . PUNCT     prob -> -48.90811053561596\n==================== new sentence ================================== \nWORD_ROW -> ἐν ADP     prob -> -5.169246101309227\nWORD_ROW -> Ἱππολύτῳ NOUN     prob -> -8.659846409034628\nWORD_ROW -> Εὐριπιδείῳ ADJ     prob -> -12.240803427960548\nWORD_ROW -> πάλιν ADV     prob -> -20.719184386417556\nWORD_ROW -> ἡ DET     prob -> -27.531738358789344\nWORD_ROW -> Ἀφροδίτη NOUN     prob -> -35.53208747583375\nWORD_ROW -> φησίν VERB     prob -> -43.756903590493984\nWORD_ROW -> · PUNCT     prob -> -46.40775482665135\n"
     ]
    }
   ],
   "source": [
    "print(\"==================== TEST ON GREEK ================================== \")\n",
    "\n",
    "for i in range(0,5):\n",
    "    print(\"==================== new sentence ================================== \")\n",
    "    backtrace_greek, probabilities_greek = viterbi(sentences_greek[i], tagset_greek, probEmission_greek, probTransition_greek, 0, statistics_greek);\n",
    "    printPosTag(sentences_greek[i], tagset_greek, backtrace_greek, probabilities_greek);"
   ]
  },
  {
   "source": [
    "TRAIN AND DECODING LATIN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences_latin, tagset_latin, probEmission_latin, probTransition_latin, statistics_latin = train(\"latin\",True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== TEST ON LATIN ================================== \nWORD_ROW -> + PUNCT     prob -> -3.0409226340125732\nWORD_ROW -> In ADP     prob -> -9.439532515808455\nWORD_ROW -> Dei PROPN     prob -> -14.211431251275023\nWORD_ROW -> nomine NOUN     prob -> -19.347702756413725\nWORD_ROW -> regnante VERB     prob -> -25.41676081668182\nWORD_ROW -> domno NOUN     prob -> -32.09007095933274\nWORD_ROW -> nostro DET     prob -> -37.32125225570135\nWORD_ROW -> Carulo PROPN     prob -> -44.352569396270525\nWORD_ROW -> rege NOUN     prob -> -50.94443448474381\nWORD_ROW -> Francorum NOUN     prob -> -59.12142501243105\nWORD_ROW -> et CCONJ     prob -> -62.08688424838046\nWORD_ROW -> Langobardorum NOUN     prob -> -69.5169467052356\nWORD_ROW -> , PUNCT     prob -> -71.71924027267977\nWORD_ROW -> anno NOUN     prob -> -77.47089829042083\nWORD_ROW -> regni NOUN     prob -> -85.09864464321117\nWORD_ROW -> eius DET     prob -> -89.89233065797255\nWORD_ROW -> quo PRON     prob -> -98.0120052842971\nWORD_ROW -> coepit VERB     prob -> -103.88455098746397\nWORD_ROW -> Langobardiam PROPN     prob -> -111.6989517354119\nWORD_ROW -> primo ADJ     prob -> -120.31805436877386\nWORD_ROW -> , PUNCT     prob -> -122.1806078002921\nWORD_ROW -> septimo ADJ     prob -> -130.6077480658951\nWORD_ROW -> decimo ADJ     prob -> -137.10431615708202\nWORD_ROW -> kalendas NOUN     prob -> -143.630340290092\nWORD_ROW -> augustas ADJ     prob -> -152.13002485574665\nWORD_ROW -> , PUNCT     prob -> -153.9925782872649\nWORD_ROW -> per ADP     prob -> -158.88516417473824\nWORD_ROW -> indictionem NOUN     prob -> -164.9927314913198\nWORD_ROW -> duodecimam ADJ     prob -> -172.91715827355114\nWORD_ROW -> . PUNCT     prob -> -175.7909476589246\n"
     ]
    }
   ],
   "source": [
    "print(\"==================== TEST ON LATIN ================================== \")\n",
    "backtrace_latin, probabilities_latin = viterbi(sentences_latin[0], tagset_latin, probEmission_latin, probTransition_latin, 4, statistics_latin);\n",
    "printPosTag(sentences_latin[0], tagset_latin, backtrace_latin, probabilities_latin);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAccuracy(language, tagset, probEmission, probTransition, smoothingType, statistics):\n",
    "    accuracy = 0;\n",
    "    sentences_test = readFile(language,\"test\");\n",
    "    count_tag_correct = 0;\n",
    "    count_total_tag = 0;\n",
    "    errors = dict();\n",
    "    for sentence in sentences_test:\n",
    "        backtrace_test, probabilities_test = viterbi(sentence, tagset, probEmission, probTransition, smoothingType, statistics);\n",
    "         #Get real tag\n",
    "        i = 0;\n",
    "        for token in sentence:\n",
    "            real_tag = token[\"upos\"];\n",
    "            if tagset.index(real_tag) == backtrace_test[i]:\n",
    "                count_tag_correct = count_tag_correct + 1;\n",
    "            else:\n",
    "                errors[token[\"form\"]] = [real_tag,tagset[backtrace_test[i]]]\n",
    "            count_total_tag = count_total_tag + 1;\n",
    "            i = i + 1;\n",
    "    accuracy = count_tag_correct/count_total_tag\n",
    "    return accuracy,errors;"
   ]
  },
  {
   "source": [
    "CALCULATE ACCURACY ON TEST SET OF GREEK"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ACCURACY GREEK  0.7366763681473353\n"
     ]
    }
   ],
   "source": [
    "accuracy_greek,errors_greek = calculateAccuracy(\"greek\", tagset_greek, probEmission_greek, probTransition_greek, 1, statistics_greek);\n",
    "print(\"ACCURACY GREEK  \" + str(accuracy_greek))\n"
   ]
  },
  {
   "source": [
    "CALCULATE ACCURACY ON TEST SET OF LATIN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ACCURACY LATIN 0.9514099422733502\n"
     ]
    }
   ],
   "source": [
    "accuracy_latin,errors_latin = calculateAccuracy(\"latin\", tagset_latin, probEmission_latin, probTransition_latin, 1, statistics_latin);\n",
    "print(\"ACCURACY LATIN \" + str(accuracy_latin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizeErrors(errors,tagset):\n",
    "    probabilites_error = dict();\n",
    "    for word in errors:\n",
    "        real_tag = errors[word][0]\n",
    "        estimate_tag = errors[word][1]\n",
    "        index_estimated_tag = tagset.index(estimate_tag);\n",
    "        if real_tag in probabilites_error.keys():\n",
    "            probabilites_error[real_tag][index_estimated_tag] = probabilites_error[real_tag][index_estimated_tag] + 1;\n",
    "        else:\n",
    "            prob_error = np.zeros(len(tagset), dtype = int);\n",
    "            prob_error[index_estimated_tag] = 1;\n",
    "            probabilites_error[real_tag] = prob_error;\n",
    "    return probabilites_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'VERB': array([   1,    0,    1,    0,    0,    0, 1815,    0,    1,    0,    0,\n",
       "           0,    0,    0]),\n",
       " 'ADV': array([ 3,  4,  0, 11,  0,  0, 91,  0, 31,  2,  0,  2,  0,  0]),\n",
       " 'PRON': array([102,   0,   1,   0,   0,   0,  37,   0,   0,   0,   0,   0,   1,\n",
       "          0]),\n",
       " 'ADJ': array([  0,   0,   3,   0,   0,   0, 754,  14,   1,  24,   0,   0,   1,\n",
       "          0]),\n",
       " 'DET': array([ 0,  0,  0,  0,  0,  0,  1,  0,  0, 20,  0,  0,  0,  1]),\n",
       " 'ADP': array([0, 0, 5, 0, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0]),\n",
       " 'SCONJ': array([ 0,  1, 12,  1,  0,  0,  2,  0,  1,  0,  0,  0,  0,  0]),\n",
       " 'NOUN': array([33,  1,  2,  0,  0,  0,  0,  0,  0,  1,  0,  0,  3,  0]),\n",
       " 'NUM': array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'CCONJ': array([0, 0, 6, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]),\n",
       " 'PUNCT': array([0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'INTJ': array([0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0]),\n",
       " 'X': array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "metadata": {},
     "execution_count": 540
    }
   ],
   "source": [
    "analizeErrors(errors_greek,tagset_greek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'VERB': array([  0,   0,   0,   7,   0,   0, 102,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]),\n",
       " 'PROPN': array([  5,   0,   0,   0,   0,   0, 271,   0,   0,   0,   0,   3,   0,\n",
       "          0,   1]),\n",
       " 'ADV': array([0, 1, 0, 0, 4, 0, 4, 1, 0, 0, 0, 0, 1, 0, 0]),\n",
       " 'DET': array([0, 1, 0, 0, 0, 0, 7, 0, 0, 6, 0, 0, 0, 0, 0]),\n",
       " 'NOUN': array([7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 5, 0]),\n",
       " 'ADP': array([1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0]),\n",
       " 'CCONJ': array([0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0]),\n",
       " 'ADJ': array([ 0,  0,  0,  0,  0,  0, 45,  0,  0,  0,  1,  0,  0,  0,  0]),\n",
       " 'NUM': array([0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'AUX': array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 4, 0]),\n",
       " 'SCONJ': array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " 'PRON': array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "metadata": {},
     "execution_count": 541
    }
   ],
   "source": [
    "analizeErrors(errors_latin,tagset_latin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}